import zarrdataset as zds

import torch
import torchvision
from torch.utils.data import DataLoader, ChainDataset
import numpy as np
import matplotlib.pyplot as plt

class AsType(object):
    def __init__(self, dtype):
        self.dtype = dtype

    def __call__(self, image):
        return image.astype(self.dtype)


if __name__ == "__main__":

    # These are images from the Image Data Resource (IDR) 
    # https://idr.openmicroscopy.org/ that are publicly available and were 
    # converted to the OME-NGFF (Zarr) format by the OME group. More examples
    # can be found at Public OME-Zarr data (Nov. 2020)
    # https://www.openmicroscopy.org/2020/11/04/zarr-data.html

    filenames = [
        "https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001240.zarr",
        "https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001241.zarr",
        "https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001242.zarr",
        "https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001243.zarr",
    ]

    patch_size = dict(Z=32, Y=64, X=64)
    patch_sampler = zds.GridPatchSampler(patch_size=patch_size)

    img_transform = torchvision.transforms.Compose([
        AsType(np.float16)
    ])

    my_datasets = [zds.ZarrDataset(filenames,
                                   transform=img_transform,
                                   data_group="0",
                                   source_axes="TCZYX",
                                   patch_sampler=patch_sampler,
                                   shuffle=True,
                                   return_any_label=False)]

    my_chained_dataset = ChainDataset(my_datasets)

    my_dataloader = DataLoader(my_chained_dataset,
                               num_workers=2,
                               batch_size=4,
                               worker_init_fn=zds.chained_zarrdataset_worker_init)

    samples = []
    for i, sample in enumerate(my_dataloader):
        # Samples generated by DataLoaders have Batch (B) as first axes
        samples.append([s for s in sample])

        print(f"Sample {i+1} with size {sample.shape}")

        if i > 5:
            # Take only five samples for illustration purposes
            break

    samples = torch.cat(samples, dim=-1)

    print("Samples size", samples.shape)
